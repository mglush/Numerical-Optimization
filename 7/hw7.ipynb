{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b109b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/Mike/desktop/UCSB/CS/CS111/cs111-2021-fall/Python\") \n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "import scipy\n",
    "from scipy import linalg as spla\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from scipy import integrate\n",
    "import networkx as nx\n",
    "import json\n",
    "import cs111\n",
    "\n",
    "import matplotlib\n",
    "# %matplotlib ipympl\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "np.set_printoptions(precision = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d7bfb",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dc429ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Q:\n",
      " [[-0.9428 -0.1421  0.3015]\n",
      " [ 0.2357 -0.9239  0.3015]\n",
      " [ 0.2357  0.3553  0.9045]]\n",
      "Matrix R:\n",
      " [[-4.2426  1.6499  1.6499]\n",
      " [ 0.     -3.9087  2.4873]\n",
      " [ 0.      0.      3.0151]]\n",
      "Is R upper-triangular? True\n",
      "Comparing Q to the Identity matrix: 2.846963623252602e-16\n",
      "Compare Q@R to A: 2.3599796770763007e-16\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "A = np.array([[4,-1,-1], [-1,4,-1], [-1,-1,4]])\n",
    "b = (np.array([15,-3,12])).T\n",
    "\n",
    "Q, R = spla.qr(A) # QR factorization\n",
    "\n",
    "print(\"Matrix Q:\\n\", Q)\n",
    "print(\"Matrix R:\\n\", R)\n",
    "print(\"Is R upper-triangular?\", (R == np.triu(R)).all())\n",
    "print(\"Comparing Q to the Identity matrix:\", npla.norm(Q.T@Q - np.eye(3))/npla.norm(np.eye(3))) # should be close to 0\n",
    "print(\"Compare Q@R to A:\", npla.norm(Q@R - A)/npla.norm(A)) # should be close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f009d47",
   "metadata": {},
   "source": [
    "$Q$ is orthogonal since the relative norm we calculated is about 0. We can see $Q@R=A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20bf177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative residual norm: 1.8835570444992786e-16\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "A = np.array([[4,-1,-1], [-1,4,-1], [-1,-1,4]])\n",
    "b = (np.array([15,-3,12])).T\n",
    "\n",
    "Q, R = spla.qr(A) # QR factorization\n",
    "\n",
    "x = cs111.Usolve(R, Q.T @ b)\n",
    "print(\"Relative residual norm:\", npla.norm(A@x-b, 2)/npla.norm(b, 2)) # should be close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92fb46a",
   "metadata": {},
   "source": [
    "The relative residual norm confirms the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0789e",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ba9771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Q1: (9, 9)\n",
      "shape of Q2: (9, 5)\n",
      "is Q1 orthogonal? 4.631876663865803e-16\n",
      "is R1 upper-triangular? True\n",
      "matrix A:\n",
      " [[0.0472 0.5952 0.8494 0.3631 0.2025]\n",
      " [0.8054 0.1349 0.1148 0.0135 0.6592]\n",
      " [0.32   0.2097 0.5914 0.9283 0.6227]\n",
      " [0.042  0.711  0.7826 0.4804 0.386 ]\n",
      " [0.6077 0.0671 0.7877 0.3788 0.2003]\n",
      " [0.8923 0.4185 0.4525 0.3604 0.3022]\n",
      " [0.8236 0.533  0.4724 0.0283 0.3636]\n",
      " [0.1116 0.3209 0.4056 0.3453 0.859 ]\n",
      " [0.5781 0.3698 0.2507 0.718  0.6832]]\n",
      "matrix Q1@R1:\n",
      " [[0.0472 0.5952 0.8494 0.3631 0.2025]\n",
      " [0.8054 0.1349 0.1148 0.0135 0.6592]\n",
      " [0.32   0.2097 0.5914 0.9283 0.6227]\n",
      " [0.042  0.711  0.7826 0.4804 0.386 ]\n",
      " [0.6077 0.0671 0.7877 0.3788 0.2003]\n",
      " [0.8923 0.4185 0.4525 0.3604 0.3022]\n",
      " [0.8236 0.533  0.4724 0.0283 0.3636]\n",
      " [0.1116 0.3209 0.4056 0.3453 0.859 ]\n",
      " [0.5781 0.3698 0.2507 0.718  0.6832]]\n",
      "relative residual norm: 6.047622595455267e-16\n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "m = 9\n",
    "n = 5\n",
    "A = np.random.rand(9, 5)\n",
    "Q1, R1 = spla.qr(A)\n",
    "A_approx = Q1@R1\n",
    "\n",
    "print(\"shape of Q1:\", Q1.shape)\n",
    "print(\"shape of Q2:\", R1.shape)\n",
    "print(\"is Q1 orthogonal?\", npla.norm(Q1.T@Q1 - np.eye(m)) / npla.norm(np.eye(m)))\n",
    "print(\"is R1 upper-triangular?\", (R1 == np.triu(R1)).all())\n",
    "print(\"matrix A:\\n\", A)\n",
    "print(\"matrix Q1@R1:\\n\", A_approx)\n",
    "print(\"relative residual norm:\", npla.norm(A_approx - A) / npla.norm(A)) # should be close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71a0ee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Q1: (9, 5)\n",
      "shape of Q2: (5, 5)\n",
      "what is Q2^T@Q2\n",
      " [[ 1.0000e+00  1.5352e-17 -3.4865e-18 -6.8722e-17 -5.9079e-17]\n",
      " [ 1.5352e-17  1.0000e+00 -2.0433e-16 -3.1941e-17 -8.8169e-17]\n",
      " [-3.4865e-18 -2.0433e-16  1.0000e+00  2.1998e-17 -6.7319e-17]\n",
      " [-6.8722e-17 -3.1941e-17  2.1998e-17  1.0000e+00 -7.2972e-17]\n",
      " [-5.9079e-17 -8.8169e-17 -6.7319e-17 -7.2972e-17  1.0000e+00]]\n",
      "is Q2 orthogonal? 2.6390697891986866e-16\n",
      "is R2 upper-triangular? True\n",
      "matrix A:\n",
      " [[0.1004 0.1639 0.1982 0.299  0.4301]\n",
      " [0.1016 0.3936 0.5534 0.7133 0.0741]\n",
      " [0.1469 0.2717 0.3984 0.6919 0.0627]\n",
      " [0.0021 0.9309 0.3762 0.8347 0.3048]\n",
      " [0.9424 0.9025 0.7814 0.4227 0.0438]\n",
      " [0.3216 0.0046 0.7103 0.5548 0.6484]\n",
      " [0.3986 0.0537 0.6666 0.6427 0.492 ]\n",
      " [0.7938 0.622  0.671  0.6532 0.6685]\n",
      " [0.3461 0.9277 0.408  0.8247 0.9557]]\n",
      "matrix Q2@R2:\n",
      " [[0.1004 0.1639 0.1982 0.299  0.4301]\n",
      " [0.1016 0.3936 0.5534 0.7133 0.0741]\n",
      " [0.1469 0.2717 0.3984 0.6919 0.0627]\n",
      " [0.0021 0.9309 0.3762 0.8347 0.3048]\n",
      " [0.9424 0.9025 0.7814 0.4227 0.0438]\n",
      " [0.3216 0.0046 0.7103 0.5548 0.6484]\n",
      " [0.3986 0.0537 0.6666 0.6427 0.492 ]\n",
      " [0.7938 0.622  0.671  0.6532 0.6685]\n",
      " [0.3461 0.9277 0.408  0.8247 0.9557]]\n",
      "relative residual norm: 2.971371969597798e-16\n",
      "forbenius norm of the difference of Q1 and Q2 0.3416407864998737\n",
      "forbenius norm of the difference of R1 and R2 0.0\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "m = 9\n",
    "n = 5\n",
    "A = np.random.rand(9, 5)\n",
    "Q1, R1 = spla.qr(A)\n",
    "Q2, R2 = spla.qr(A, mode = 'economic')\n",
    "A_approx = Q2@R2\n",
    "\n",
    "print(\"shape of Q1:\", Q2.shape)\n",
    "print(\"shape of Q2:\", R2.shape)\n",
    "print(\"what is Q2^T@Q2\\n\", Q2.T@Q2)\n",
    "print(\"is Q2 orthogonal?\", npla.norm(Q2.T@Q2 - np.eye(n)) / npla.norm(np.eye(n)))\n",
    "print(\"is R2 upper-triangular?\", (R2 == np.triu(R2)).all())\n",
    "print(\"matrix A:\\n\", A)\n",
    "print(\"matrix Q2@R2:\\n\", A_approx)\n",
    "print(\"relative residual norm:\", npla.norm(A_approx - A) / npla.norm(A))\n",
    "print(\"forbenius norm of the difference of Q1 and Q2\", (npla.norm(Q1) - npla.norm(Q2))/npla.norm(Q2))\n",
    "print(\"forbenius norm of the difference of R1 and R2\", (npla.norm(R1) - npla.norm(R2))/npla.norm(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a1aeb3",
   "metadata": {},
   "source": [
    "We generate the economy-sized QR factorization of $A$, confirm that $Q_2$ is orthogonal, confirm by inspection that $R_2$ is, in fact, upper-triangular, and then verify that $Q_2R_2=A$. We can clearly see from this problem that $Q_2$ is exactly matrix $Q_1$, truncated to be an $m$-by-$n$ matrix (since $Q_1$ is $m$-by-$m$). This truncation results in the forbenius norm of $0.3416$, since we truncate nonzero values from matrix $Q_1$ in the process.\\newline\n",
    "As for $R_1$ and $R_2$, $R_2$ is the same matrix as $R_1$, truncated to be $n$-by$n$. The forbenius norm here is $0$ since we truncate $0$s from $R_1$ to obtain $R_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4361a8",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d4e150a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 0.9327 -0.7539 -0.9112  1.6088  0.167 ]\n",
      "relative residual norm: 0.2874629614360627\n",
      "Verifying orthogonality: 4.778535933284633e-15\n"
     ]
    }
   ],
   "source": [
    "# generate the random 9x1 vector\n",
    "b = np.random.rand(m)\n",
    "\n",
    "# 3.1\n",
    "x = npla.lstsq(A, b, rcond = None)[0] # computing x here\n",
    "r = b - A@x                           # calculate the residual\n",
    "print(\"x:\", x)\n",
    "print(\"relative residual norm:\", npla.norm(r, 2)/npla.norm(b, 2))\n",
    "\n",
    "# verify the residual is orthogonal\n",
    "print(\"Verifying orthogonality:\", npla.norm(A.T@r, 2)) # should be close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19fff076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 0.9327 -0.7539 -0.9112  1.6088  0.167 ]\n",
      "relative residual norm: 0.28746296143606265\n",
      "Verifying orthogonality: 9.606120695417352e-16\n"
     ]
    }
   ],
   "source": [
    "# 3.2\n",
    "y = Q1.T@b\n",
    "x = cs111.Usolve(R1[:min(A.shape)], y[:min(A.shape)]) # compute x\n",
    "r = b - A@x                           # calculate the residual\n",
    "print(\"x:\", x)\n",
    "print(\"relative residual norm:\", npla.norm(r, 2)/npla.norm(b, 2))\n",
    "\n",
    "# verify the residual is orthogonal\n",
    "print(\"Verifying orthogonality:\", npla.norm(A.T@r, 2)) # should be close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6994053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 0.9327 -0.7539 -0.9112  1.6088  0.167 ]\n",
      "relative residual norm: 0.28746296143606265\n",
      "Verifying orthogonality: 9.606120695417352e-16\n"
     ]
    }
   ],
   "source": [
    "# 3.3\n",
    "y = Q2.T@b\n",
    "x = cs111.Usolve(R2, y) # compute x\n",
    "r = b - A@x                           # calculate the residual\n",
    "print(\"x:\", x)\n",
    "print(\"relative residual norm:\", npla.norm(r, 2)/npla.norm(b, 2))\n",
    "\n",
    "# verify the residual is orthogonal\n",
    "print(\"Verifying orthogonality:\", npla.norm(A.T@r, 2)) # should be close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2beece",
   "metadata": {},
   "source": [
    "We can see that $\\textbf{3.3}$ gives us the same result as $\\textbf{3.2}$ and $\\textbf{3.1}$ do. This is because in $\\textbf{3.2}$, we use QR factorization, then extract a submatrix from $R_1$, and slice y to craft the input for Usolve. In $\\textbf{3.3}$ we basically do the reverse, where the QR factorization takes care of the dimension issue by providing a square $R_2$ for us (ends up being exactly the same matrix as the one we extracted from $R_1$); the truncation in $\\textbf{3.2}$ makes the y input also be exactly the same as the y input in $\\textbf{3.3}$. These answers are the same as $\\textbf{3.1}$ because this is precisely what npla.lstsq() does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "70fb9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1. 1. 1. 1. 1.]\n",
      "relative residual norm: 1.217749711047603e-16\n",
      "Verifying orthogonality: 1.5600859208672382e-15\n"
     ]
    }
   ],
   "source": [
    "# 3.4\n",
    "b = A@np.ones(5)# change b\n",
    "\n",
    "y = Q2.T@b\n",
    "x = cs111.Usolve(R2, y) # compute x\n",
    "r = b - A@x                           # calculate the residual\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"relative residual norm:\", npla.norm(r, 2)/npla.norm(b, 2))\n",
    "print(\"Verifying orthogonality:\", npla.norm(A.T@r, 2)) # should be close to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a09409",
   "metadata": {},
   "source": [
    "The new relative residual norm is much smaller in $\\textbf{3.4}$ than the relative residual norms in the other sections of problem $3$. Since our $b$ is a linear combination of $A$'s columns, no round-off error happens during QR factorization; we can see this by examining $Q_2$ and $R_2$, and seeing that unlike other sections, there's only 4 digits of precision necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
